# üéØ **FASE 3 - ENSEMBLE E OTIMIZA√á√ÉO [PLANEJADA]**

## üéØ **STATUS: AGUARDANDO CONCLUS√ÉO DA FASE 2**

### **Dura√ß√£o:** 2-3 semanas
### **Objetivo:** Criar ensemble avan√ßado com otimiza√ß√£o autom√°tica de pesos
### **Performance Target:** >70% com baixa volatilidade

---

## üß† **FUNDAMENTA√á√ÉO TE√ìRICA ENSEMBLE**

### **Hip√≥tese Central:**
**"Combina√ß√£o inteligente de modelos independentes supera performance individual"**

### **Base Cient√≠fica:**
- **Teorema do Ensemble**: Erro diminui com diversifica√ß√£o
- **Bias-Variance Tradeoff**: Ensemble reduz vari√¢ncia mantendo bias
- **Condorcet's Jury Theorem**: Maioria de classificadores independentes
- **Portfolio Theory**: Otimiza√ß√£o de Markowitz adaptada para modelos

### **Diversifica√ß√£o de Estrat√©gias:**
```
MetronomoModel        ‚Üí Frequencista (explora padr√µes)
AntiFrequencySimple   ‚Üí Anti-frequencista b√°sico
StatisticalDebt       ‚Üí Fundamentalista (d√≠vida estat√≠stica)
Saturation           ‚Üí T√©cnico (indicadores de revers√£o)
PendularOscillator   ‚Üí F√≠sico (an√°lise de ciclos)
```

---

## üìã **DELIVERABLES DA FASE 3**

### **üéØ SISTEMA DE ENSEMBLE AVAN√áADO**

#### **1. AdvancedEnsembleModel.cs**
```csharp
// Localiza√ß√£o: Library/PredictionModels/Composite/AdvancedEnsembleModel.cs
// Complexidade: ‚≠ê‚≠ê‚≠ê‚≠ê Alta (otimiza√ß√£o multi-objetivo)

public class AdvancedEnsembleModel : PredictionModelBase, IEnsembleModel, IAdaptiveModel
{
    public override string ModelName => "Ensemble Avan√ßado";
    public override string ModelType => "Composite-Advanced";
    
    // Estrat√©gias de combina√ß√£o dispon√≠veis
    public enum CombinationStrategy
    {
        WeightedAverage,     // M√©dia ponderada simples
        Stacking,            // Meta-modelo para combina√ß√£o
        Voting,              // Sistema de vota√ß√£o
        BayesianAverage,     // M√©dia bayesiana
        DynamicWeighting,    // Pesos adaptativos
        RegimeAware          // Consciente de regimes de mercado
    }
}
```

#### **üß© Algoritmos de Combina√ß√£o:**

##### **A) Weighted Average (Baseline):**
```csharp
public async Task<PredictionResult> WeightedAverageAsync(int concurso)
{
    var scores = new Dictionary<int, double>();
    var confidenceTotal = 0.0;
    
    foreach (var model in SubModels)
    {
        var result = await model.PredictAsync(concurso);
        var weight = ModelWeights[model.ModelName] * result.Confidence;
        confidenceTotal += weight;
        
        foreach (var number in result.PredictedNumbers)
        {
            scores[number] = scores.GetValueOrDefault(number, 0) + weight;
        }
    }
    
    // Normalizar scores
    var normalizedScores = scores.ToDictionary(
        kvp => kvp.Key, 
        kvp => kvp.Value / confidenceTotal
    );
    
    return SelectTopNumbers(normalizedScores, 15);
}
```

##### **B) Stacking com Meta-Modelo:**
```csharp
public class StackingEnsemble : AdvancedEnsembleModel
{
    private IMetaLearningModel _metaModel;
    
    public async Task<PredictionResult> StackingAsync(int concurso)
    {
        // N√≠vel 1: Predi√ß√µes dos modelos base
        var baseResults = new List<PredictionResult>();
        foreach (var model in SubModels)
        {
            var result = await model.PredictAsync(concurso);
            baseResults.Add(result);
        }
        
        // N√≠vel 2: Meta-modelo combina as predi√ß√µes
        var features = ExtractFeaturesFromResults(baseResults);
        var metaPrediction = await _metaModel.PredictAsync(features);
        
        return metaPrediction;
    }
    
    private Dictionary<string, double> ExtractFeaturesFromResults(List<PredictionResult> results)
    {
        var features = new Dictionary<string, double>();
        
        foreach (var result in results)
        {
            features[$"{result.ModelName}_Confidence"] = result.Confidence;
            features[$"{result.ModelName}_TopNumber"] = result.PredictedNumbers.First();
            features[$"{result.ModelName}_Diversity"] = CalculateDiversity(result.PredictedNumbers);
            // ... mais features
        }
        
        return features;
    }
}
```

##### **C) Voting System:**
```csharp
public async Task<PredictionResult> VotingAsync(int concurso)
{
    var votes = new Dictionary<int, VoteInfo>();
    
    foreach (var model in SubModels)
    {
        var result = await model.PredictAsync(concurso);
        var weight = ModelWeights[model.ModelName];
        
        for (int i = 0; i < result.PredictedNumbers.Count; i++)
        {
            var number = result.PredictedNumbers[i];
            var position = i + 1; // 1-15
            var positionWeight = (16 - position) / 15.0; // Peso decrescente por posi√ß√£o
            
            if (!votes.ContainsKey(number))
                votes[number] = new VoteInfo();
                
            votes[number].TotalVotes += weight * positionWeight;
            votes[number].VotingModels.Add(model.ModelName);
            votes[number].AveragePosition += position;
        }
    }
    
    // Normalizar e selecionar
    foreach (var vote in votes.Values)
    {
        vote.AveragePosition /= vote.VotingModels.Count;
    }
    
    var selectedNumbers = votes
        .OrderByDescending(kvp => kvp.Value.TotalVotes)
        .Take(15)
        .Select(kvp => kvp.Key)
        .OrderBy(x => x)
        .ToList();
    
    return new PredictionResult
    {
        ModelName = ModelName,
        PredictedNumbers = selectedNumbers,
        Confidence = CalculateVotingConfidence(votes),
        VotingDetails = votes
    };
}
```

##### **D) Dynamic Weighting:**
```csharp
public class DynamicWeightingEnsemble : AdvancedEnsembleModel
{
    private Dictionary<string, Queue<double>> _recentPerformance;
    private readonly int _performanceWindow = 20;
    
    public async Task<PredictionResult> DynamicWeightingAsync(int concurso)
    {
        // Atualizar pesos baseado em performance recente
        UpdateDynamicWeights();
        
        // Aplicar decaimento temporal aos pesos
        var temporalWeights = ApplyTemporalDecay();
        
        // Combinar com pesos base
        var finalWeights = CombineWeights(ModelWeights, temporalWeights);
        
        return await WeightedAverageWithWeights(concurso, finalWeights);
    }
    
    private void UpdateDynamicWeights()
    {
        foreach (var model in SubModels)
        {
            var recentPerf = CalculateRecentPerformance(model.ModelName);
            
            if (!_recentPerformance.ContainsKey(model.ModelName))
                _recentPerformance[model.ModelName] = new Queue<double>();
                
            var queue = _recentPerformance[model.ModelName];
            queue.Enqueue(recentPerf);
            
            if (queue.Count > _performanceWindow)
                queue.Dequeue();
                
            // Ajustar peso baseado na tend√™ncia de performance
            var trend = CalculatePerformanceTrend(queue);
            var adjustment = Math.Tanh(trend) * 0.2; // ¬±20% ajuste m√°ximo
            
            ModelWeights[model.ModelName] = Math.Max(0.05, 
                ModelWeights[model.ModelName] * (1 + adjustment));
        }
        
        // Renormalizar pesos
        NormalizeWeights();
    }
}
```

---

### **‚öôÔ∏è SISTEMA DE OTIMIZA√á√ÉO DE PESOS**

#### **1. WeightOptimizer.cs**
```csharp
// Localiza√ß√£o: Library/Services/Optimization/WeightOptimizer.cs

public class WeightOptimizer : IWeightOptimizer
{
    public enum OptimizationMethod
    {
        GridSearch,          // Busca em grade
        GeneticAlgorithm,    // Algoritmo gen√©tico
        ParticleSwarm,       // Enxame de part√≠culas
        BayesianOptimization, // Otimiza√ß√£o bayesiana
        GradientDescent,     // Descida do gradiente
        SimulatedAnnealing   // Recozimento simulado
    }
}
```

##### **A) Grid Search (Baseline):**
```csharp
public async Task<Dictionary<string, double>> GridSearchAsync(
    List<IPredictionModel> models, 
    Lances validationData,
    GridSearchParams parameters)
{
    var bestWeights = new Dictionary<string, double>();
    var bestPerformance = 0.0;
    
    var combinations = GenerateWeightCombinations(models, parameters);
    
    foreach (var weights in combinations)
    {
        var performance = await EvaluateWeights(weights, models, validationData);
        
        if (performance.Accuracy > bestPerformance)
        {
            bestPerformance = performance.Accuracy;
            bestWeights = new Dictionary<string, double>(weights);
        }
    }
    
    return bestWeights;
}

private IEnumerable<Dictionary<string, double>> GenerateWeightCombinations(
    List<IPredictionModel> models, GridSearchParams parameters)
{
    var modelNames = models.Select(m => m.ModelName).ToList();
    var steps = parameters.Steps;
    var minWeight = parameters.MinWeight;
    var maxWeight = parameters.MaxWeight;
    
    return GenerateRecursive(modelNames, 0, new Dictionary<string, double>(), 
                           steps, minWeight, maxWeight);
}
```

##### **B) Genetic Algorithm:**
```csharp
public class GeneticWeightOptimizer : WeightOptimizer
{
    public async Task<Dictionary<string, double>> GeneticAlgorithmAsync(
        List<IPredictionModel> models,
        Lances validationData,
        GeneticParams parameters)
    {
        var population = InitializePopulation(models.Count, parameters.PopulationSize);
        
        for (int generation = 0; generation < parameters.MaxGenerations; generation++)
        {
            // Avaliar fitness de cada indiv√≠duo
            var fitness = await EvaluatePopulation(population, models, validationData);
            
            // Sele√ß√£o dos melhores
            var selected = Selection(population, fitness, parameters.SelectionRate);
            
            // Crossover
            var offspring = Crossover(selected, parameters.CrossoverRate);
            
            // Muta√ß√£o
            Mutation(offspring, parameters.MutationRate);
            
            // Nova popula√ß√£o
            population = selected.Concat(offspring).Take(parameters.PopulationSize).ToList();
            
            // Log do progresso
            var bestFitness = fitness.Max();
            Console.WriteLine($"Generation {generation}: Best fitness = {bestFitness:F4}");
        }
        
        var bestIndividual = population[fitness.ToList().IndexOf(fitness.Max())];
        return ConvertToWeights(bestIndividual, models);
    }
    
    private List<double[]> Crossover(List<double[]> parents, double crossoverRate)
    {
        var offspring = new List<double[]>();
        
        for (int i = 0; i < parents.Count - 1; i += 2)
        {
            if (_random.NextDouble() < crossoverRate)
            {
                var (child1, child2) = UniformCrossover(parents[i], parents[i + 1]);
                offspring.Add(child1);
                offspring.Add(child2);
            }
        }
        
        return offspring;
    }
    
    private void Mutation(List<double[]> individuals, double mutationRate)
    {
        foreach (var individual in individuals)
        {
            for (int i = 0; i < individual.Length; i++)
            {
                if (_random.NextDouble() < mutationRate)
                {
                    // Muta√ß√£o gaussiana
                    individual[i] += _random.NextGaussian() * 0.1;
                    individual[i] = Math.Max(0, Math.Min(1, individual[i]));
                }
            }
            
            // Renormalizar para que soma = 1
            NormalizeWeights(individual);
        }
    }
}
```

##### **C) Bayesian Optimization:**
```csharp
public class BayesianWeightOptimizer : WeightOptimizer
{
    private GaussianProcessRegressor _surrogate;
    private List<(double[] weights, double performance)> _observations;
    
    public async Task<Dictionary<string, double>> BayesianOptimizationAsync(
        List<IPredictionModel> models,
        Lances validationData,
        BayesianParams parameters)
    {
        _observations = new List<(double[], double)>();
        
        // Inicializa√ß√£o com pontos aleat√≥rios
        for (int i = 0; i < parameters.InitialPoints; i++)
        {
            var weights = GenerateRandomWeights(models.Count);
            var performance = await EvaluateWeights(ConvertToWeights(weights, models), 
                                                  models, validationData);
            _observations.Add((weights, performance.Accuracy));
        }
        
        // Itera√ß√µes principais
        for (int iter = 0; iter < parameters.MaxIterations; iter++)
        {
            // Treinar modelo surrogate
            _surrogate.Fit(_observations.Select(o => o.weights).ToArray(),
                          _observations.Select(o => o.performance).ToArray());
            
            // Encontrar pr√≥ximo ponto via acquisition function
            var nextWeights = OptimizeAcquisition(parameters.AcquisitionFunction);
            
            // Avaliar ponto real
            var actualPerformance = await EvaluateWeights(
                ConvertToWeights(nextWeights, models), models, validationData);
                
            _observations.Add((nextWeights, actualPerformance.Accuracy));
            
            Console.WriteLine($"Iteration {iter}: Best so far = {_observations.Max(o => o.performance):F4}");
        }
        
        var bestObservation = _observations.OrderByDescending(o => o.performance).First();
        return ConvertToWeights(bestObservation.weights, models);
    }
    
    private double[] OptimizeAcquisition(AcquisitionFunction function)
    {
        // Expected Improvement ou Upper Confidence Bound
        var bestWeights = new double[_observations.First().weights.Length];
        var bestAcquisition = double.MinValue;
        
        // Otimiza√ß√£o via BFGS ou similar
        for (int trial = 0; trial < 1000; trial++)
        {
            var candidateWeights = GenerateRandomWeights(bestWeights.Length);
            var acquisition = CalculateAcquisition(candidateWeights, function);
            
            if (acquisition > bestAcquisition)
            {
                bestAcquisition = acquisition;
                bestWeights = candidateWeights;
            }
        }
        
        return bestWeights;
    }
}
```

---

### **üìä SISTEMA DE AN√ÅLISE DE DIVERSIFICA√á√ÉO**

#### **1. DiversificationAnalyzer.cs**
```csharp
// Localiza√ß√£o: Library/Services/Analysis/DiversificationAnalyzer.cs

public class DiversificationAnalyzer : IDiversificationAnalyzer
{
    public DiversificationReport AnalyzeEnsemble(List<IPredictionModel> models, Lances testData)
    {
        var report = new DiversificationReport();
        
        // 1. Matriz de Correla√ß√£o
        report.CorrelationMatrix = CalculateCorrelationMatrix(models, testData);
        
        // 2. Diversifica√ß√£o por Pares
        report.PairwiseDiversification = CalculatePairwiseDiversification(models, testData);
        
        // 3. M√©tricas de Ensemble
        report.EnsembleDiversity = CalculateEnsembleDiversity(models, testData);
        report.EffectiveDiversity = CalculateEffectiveDiversity(report.CorrelationMatrix);
        
        // 4. An√°lise de Contribui√ß√£o Individual
        report.IndividualContributions = AnalyzeIndividualContributions(models, testData);
        
        return report;
    }
    
    private double[,] CalculateCorrelationMatrix(List<IPredictionModel> models, Lances testData)
    {
        var predictions = new Dictionary<string, List<List<int>>>();
        
        // Coletar predi√ß√µes de todos os modelos
        foreach (var model in models)
        {
            predictions[model.ModelName] = new List<List<int>>();
            
            foreach (var lance in testData.Take(50)) // Amostra para an√°lise
            {
                var result = model.PredictAsync(lance.Id + 1).Result;
                predictions[model.ModelName].Add(result.PredictedNumbers);
            }
        }
        
        // Calcular correla√ß√µes par-a-par
        var correlationMatrix = new double[models.Count, models.Count];
        
        for (int i = 0; i < models.Count; i++)
        {
            for (int j = 0; j < models.Count; j++)
            {
                if (i == j)
                {
                    correlationMatrix[i, j] = 1.0;
                }
                else
                {
                    var correlation = CalculatePredictionCorrelation(
                        predictions[models[i].ModelName],
                        predictions[models[j].ModelName]
                    );
                    correlationMatrix[i, j] = correlation;
                }
            }
        }
        
        return correlationMatrix;
    }
    
    private double CalculatePredictionCorrelation(List<List<int>> pred1, List<List<int>> pred2)
    {
        var overlaps = new List<double>();
        
        for (int i = 0; i < pred1.Count; i++)
        {
            var intersection = pred1[i].Intersect(pred2[i]).Count();
            var overlap = intersection / 15.0; // Overlap normalizado
            overlaps.Add(overlap);
        }
        
        return overlaps.Average();
    }
    
    private double CalculateEffectiveDiversity(double[,] correlationMatrix)
    {
        // Baseado na teoria de portfolio: diversifica√ß√£o efetiva
        int n = correlationMatrix.GetLength(0);
        double avgCorrelation = 0;
        int pairs = 0;
        
        for (int i = 0; i < n; i++)
        {
            for (int j = i + 1; j < n; j++)
            {
                avgCorrelation += correlationMatrix[i, j];
                pairs++;
            }
        }
        
        avgCorrelation /= pairs;
        
        // Diversifica√ß√£o efetiva = N / (1 + (N-1) * correla√ß√£o_m√©dia)
        return n / (1 + (n - 1) * avgCorrelation);
    }
}
```

---

### **üéõÔ∏è SISTEMA DE REGIME DETECTION**

#### **1. RegimeDetector.cs**
```csharp
// Localiza√ß√£o: Library/Services/Analysis/RegimeDetector.cs

public class RegimeDetector : IRegimeDetector
{
    public enum MarketRegime
    {
        Trending,           // Tend√™ncia clara (frequencista favor√°vel)
        Reverting,          // Revers√£o √† m√©dia (anti-freq favor√°vel)  
        Sideways,           // Lateral (ensemble balanceado)
        Volatile,           // Alta volatilidade (modelos conservadores)
        Transitional        // Mudan√ßa de regime (adapta√ß√£o necess√°ria)
    }
    
    public RegimeAnalysis DetectCurrentRegime(Lances recentData, int windowSize = 50)
    {
        var window = recentData.TakeLast(windowSize);
        
        // 1. An√°lise de Tend√™ncia
        var trendStrength = CalculateTrendStrength(window);
        var trendDirection = CalculateTrendDirection(window);
        
        // 2. An√°lise de Volatilidade  
        var volatility = CalculateVolatility(window);
        var volatilityRegime = ClassifyVolatility(volatility);
        
        // 3. An√°lise de Momentum
        var momentum = CalculateMomentum(window);
        var momentumRegime = ClassifyMomentum(momentum);
        
        // 4. Detec√ß√£o de Mudan√ßa de Regime
        var regimeChangeProb = DetectRegimeChange(window);
        
        // 5. Classifica√ß√£o Final
        var regime = ClassifyRegime(trendStrength, volatilityRegime, momentumRegime);
        
        return new RegimeAnalysis
        {
            CurrentRegime = regime,
            TrendStrength = trendStrength,
            TrendDirection = trendDirection,
            Volatility = volatility,
            Momentum = momentum,
            RegimeChangeProb = regimeChangeProb,
            RecommendedWeights = GetRegimeOptimalWeights(regime),
            Confidence = CalculateRegimeConfidence(regime, window)
        };
    }
    
    private Dictionary<string, double> GetRegimeOptimalWeights(MarketRegime regime)
    {
        return regime switch
        {
            MarketRegime.Trending => new()
            {
                ["MetronomoModel"] = 0.4,        // Favorece frequencista
                ["AntiFrequencySimple"] = 0.15,
                ["StatisticalDebt"] = 0.15,
                ["Saturation"] = 0.15,
                ["PendularOscillator"] = 0.15
            },
            
            MarketRegime.Reverting => new()
            {
                ["MetronomoModel"] = 0.15,       // Favorece anti-frequencistas
                ["AntiFrequencySimple"] = 0.3,
                ["StatisticalDebt"] = 0.25,
                ["Saturation"] = 0.2,
                ["PendularOscillator"] = 0.1
            },
            
            MarketRegime.Sideways => new()
            {
                ["MetronomoModel"] = 0.2,        // Balanceado
                ["AntiFrequencySimple"] = 0.2,
                ["StatisticalDebt"] = 0.2,
                ["Saturation"] = 0.2,
                ["PendularOscillator"] = 0.2
            },
            
            MarketRegime.Volatile => new()
            {
                ["MetronomoModel"] = 0.3,        // Modelos mais est√°veis
                ["AntiFrequencySimple"] = 0.1,
                ["StatisticalDebt"] = 0.3,
                ["Saturation"] = 0.1,
                ["PendularOscillator"] = 0.2
            },
            
            _ => GetDefaultWeights() // Transitional ou unknown
        };
    }
}
```

---

## üìä **CRONOGRAMA DA FASE 3**

### **üìÖ SEMANA 1 - Ensemble Avan√ßado**
```
Dia 1-2: AdvancedEnsembleModel com m√∫ltiplas estrat√©gias
Dia 3: Sistema de Stacking com meta-modelo
Dia 4: Sistema de Voting avan√ßado
Dia 5: Dynamic Weighting implementation
```

### **üìÖ SEMANA 2 - Otimiza√ß√£o de Pesos**
```
Dia 6-7: Grid Search e Genetic Algorithm
Dia 8: Bayesian Optimization
Dia 9: Particle Swarm e Simulated Annealing
Dia 10: Benchmarking de m√©todos de otimiza√ß√£o
```

### **üìÖ SEMANA 3 - An√°lise e Interface**
```
Dia 11-12: DiversificationAnalyzer completo
Dia 13: RegimeDetector e adaptive weighting
Dia 14: Interface avan√ßada para an√°lise
Dia 15: Valida√ß√£o final e otimiza√ß√£o
```

---

## üéØ **CRIT√âRIOS DE SUCESSO DA FASE 3**

### **‚úÖ FUNCIONAIS**
- [ ] Ensemble com 5+ estrat√©gias de combina√ß√£o
- [ ] Sistema de otimiza√ß√£o autom√°tica de pesos
- [ ] Detec√ß√£o de regimes de mercado
- [ ] Interface avan√ßada para an√°lise

### **üìä PERFORMANCE**
- [ ] Ensemble performance >70%
- [ ] Redu√ß√£o de volatilidade vs modelos individuais
- [ ] Robustez em diferentes per√≠odos hist√≥ricos
- [ ] Adapta√ß√£o autom√°tica a mudan√ßas

### **üîß T√âCNICOS**
- [ ] Otimiza√ß√£o converge em <10 itera√ß√µes
- [ ] Sistema de cache para performance
- [ ] Parallel processing para backtesting
- [ ] API para configura√ß√£o externa

### **üíº NEG√ìCIO**
- [ ] Dashboard interativo de an√°lise
- [ ] Relat√≥rios autom√°ticos de diversifica√ß√£o
- [ ] Sistema de alertas para mudan√ßas de regime
- [ ] Export para ferramentas externas

---

## üìã **ARQUIVOS A SEREM CRIADOS**

### **üéØ Ensemble Avan√ßado:**
```
Library/PredictionModels/Composite/
‚îú‚îÄ‚îÄ AdvancedEnsembleModel.cs         ‚Üê M√∫ltiplas estrat√©gias
‚îú‚îÄ‚îÄ StackingEnsemble.cs              ‚Üê Meta-modelo
‚îú‚îÄ‚îÄ VotingEnsemble.cs                ‚Üê Sistema de vota√ß√£o
‚îú‚îÄ‚îÄ DynamicEnsemble.cs               ‚Üê Pesos adaptativos
‚îî‚îÄ‚îÄ RegimeAwareEnsemble.cs           ‚Üê Consciente de regimes
```

### **‚öôÔ∏è Otimiza√ß√£o:**
```
Library/Services/Optimization/
‚îú‚îÄ‚îÄ WeightOptimizer.cs               ‚Üê Interface base
‚îú‚îÄ‚îÄ GridSearchOptimizer.cs           ‚Üê Busca em grade
‚îú‚îÄ‚îÄ GeneticOptimizer.cs              ‚Üê Algoritmo gen√©tico
‚îú‚îÄ‚îÄ BayesianOptimizer.cs             ‚Üê Otimiza√ß√£o bayesiana
‚îú‚îÄ‚îÄ ParticleSwarmOptimizer.cs        ‚Üê Enxame de part√≠culas
‚îî‚îÄ‚îÄ OptimizationResult.cs            ‚Üê Resultados padronizados
```

### **üìä An√°lise:**
```
Library/Services/Analysis/
‚îú‚îÄ‚îÄ DiversificationAnalyzer.cs       ‚Üê An√°lise de diversifica√ß√£o
‚îú‚îÄ‚îÄ RegimeDetector.cs                ‚Üê Detec√ß√£o de regimes
‚îú‚îÄ‚îÄ PerformanceAnalyzer.cs           ‚Üê An√°lise expandida
‚îú‚îÄ‚îÄ RiskAnalyzer.cs                  ‚Üê An√°lise de risco
‚îî‚îÄ‚îÄ BacktestingFramework.cs          ‚Üê Framework expandido
```

### **üñ•Ô∏è Interface Avan√ßada:**
```
Dashboard/ViewModels/Advanced/
‚îú‚îÄ‚îÄ EnsembleAnalysisViewModel.cs     ‚Üê An√°lise de ensemble
‚îú‚îÄ‚îÄ OptimizationViewModel.cs         ‚Üê Controle de otimiza√ß√£o
‚îú‚îÄ‚îÄ RegimeAnalysisViewModel.cs       ‚Üê An√°lise de regimes
‚îî‚îÄ‚îÄ PerformanceDashboardViewModel.cs ‚Üê Dashboard completo

Dashboard/Views/Advanced/
‚îú‚îÄ‚îÄ EnsembleAnalysisWindow.xaml      ‚Üê Interface de an√°lise
‚îú‚îÄ‚îÄ OptimizationControl.xaml         ‚Üê Controles de otimiza√ß√£o
‚îú‚îÄ‚îÄ PerformanceCharts.xaml           ‚Üê Gr√°ficos avan√ßados
‚îî‚îÄ‚îÄ RegimeIndicator.xaml             ‚Üê Indicador de regime
```

---

## üöÄ **PREPARA√á√ÉO PARA FASE 4**

### **üìà Base para IA Avan√ßada:**
- ‚úÖ **Ensemble robusto** com >70% performance
- ‚úÖ **Sistema de otimiza√ß√£o** autom√°tica
- ‚úÖ **Framework de an√°lise** completo
- ‚úÖ **Detec√ß√£o de regimes** para adapta√ß√£o
- ‚úÖ **Pipeline de dados** estruturado para ML

### **üéØ Performance Target:**
- **Ensemble**: >70% accuracy
- **Volatilidade**: <3% desvio padr√£o
- **Sharpe Ratio**: >1.5
- **Maximum Drawdown**: <10%

**Status: üîÆ AGUARDANDO CONCLUS√ÉO DA FASE 2**